---
title: "네이버 뉴스 분석"
author: "Jade"
date: '2019년 4월 9일 '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=F, message=F}
library(dplyr)
library(stringi)
library(tm)
library(ggplot2)
library(RColorBrewer)
library(wordcloud)
library(arules); library(igraph); library(combinat)
library(arulesViz); library(visNetwork)
library(rvest); library(httr); library(stringr)

dyn.load(paste0(system2('/usr/libexec/java_home', stdout = TRUE), 
                '/jre/lib/server/libjvm.dylib'))
library(rJava)
library(KoNLP)


removeStopword = function(t) {
  t = gsub('[[:alnum:]]+@[[:alnum:].]+', '', t)  # email 제거
  t = gsub("http[s]?://[[:alnum:].\\/\\-]+", "", t) 
  t = gsub("[[:cntrl:]]", "", t) 
  t = gsub("&[[:alnum:]]+;", "", t)
  t = gsub("@[[:alnum:]]+", "", t)
  t = gsub("@[[:alnum:]]+[:]?", "", t)
  t = gsub("[ㄱ-ㅎㅏ-ㅣ]","",t) 
  t = gsub("\\s{2,}", " ", t) 
  t = gsub("[[:punct:]]", "", t)  
  t = gsub("https", "", t)
  t = gsub("RT", "", t)
  t = gsub("\\s{2,}", " ", t) 
  # mac: emo 제거s
  gsub('\\p{So}|\\p{Cn}', '', t, perl = TRUE)
}

getNewsContent = function(uuu) { 
  h = read_html(uuu)
  hh = html_nodes(h, '#articleBodyContents')
  rr = repair_encoding(html_text(hh))
  ch = html_children(hh)
  for (i in 1:length(ch)) {
    chtxt = html_text(ch[i])
    if (chtxt == "") next
    rr = stri_replace_all(rr, "", fixed=html_text(ch[i]))
  }
  rr
  removeStopword(rr)
}

```

# 1. scrap the naver news
```{r message=F}
newsUrl = "https://news.naver.com/main/home.nhn"
html = read_html(newsUrl)
links1 = html_attr(html_nodes(html, '.newsnow_tx_inner a'), 'href')
links2 = html_attr(html_nodes(html, '.mlist2.no_bg a'), 'href')
links = c(links1, links2)
head(links)

news = c()
for (i in 1:length(links)) {
  try({
    if (regexpr('hotissue', links[i]) != -1 || regexpr('live', links[i]) != -1)
      next
    
    news = c(news, str_trim(getNewsContent(links[i])))
  }, silent = F)
}

head(news)
```


# 2. wordcloud 작도
```{r message=F, warning=F}
# mac: 한글
theme_set(theme_gray(base_family="AppleGothic"))
par(family = "AppleGothic")

wc = sapply(news, extractNoun, USE.NAMES = F)
wc1 = unlist(wc)
wc1 = wc1[ nchar(wc1) > 1 ]
wc1 = table(wc1)
wc2 = head(sort(wc1, decreasing = T), 100)

pal = brewer.pal(9, "Set1")

wordcloud(names(wc2), freq=wc2, scale=c(5,0.5),  min.freq = 1,
          random.order = F, random.color = T, colors = pal)
```

# 3. 수집 된 뉴스로 연관성 분석 및 작도
```{r warning=F, message=F, echo=F}
nouns = sapply(wc, function(x) {
  Filter(function(y='') { nchar(y) <= 4 && nchar(y) > 1 && is.hangul(y) }, x)
})

nouns1 = c()
for (j in 1:length(nouns)) {
  if (length(nouns[[j]]) == 0) next
  
  nouns1 = c(nouns1, nouns[j])
}


wtrans = as(nouns1, "transactions")
rules = apriori(wtrans, parameter = list(supp=0.1, conf=0.5))

theme_set(theme_gray(base_family="AppleGothic"))
par(family = "AppleGothic")

subrules2 <- head(sort(rules, by="confidence"), 30)
ig <- plot( subrules2, method="graph", control=list(type="items") )

ig_df <- get.data.frame( ig, what = "both" )

visNetwork(
  nodes = data.frame(id = ig_df$vertices$name,
                     value = ig_df$vertices$support, ig_df$vertices),
  edges = ig_df$edges
) %>% visEdges(ig_df$edges) %>%visOptions( highlightNearest = T )
```

